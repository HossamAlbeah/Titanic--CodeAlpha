# -*- coding: utf-8 -*-
"""Titanic .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TfOeu8pkKgxR6yc3uJwdHZsI1jAs9flK

**Import Library**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.tree     import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import  SVC

from sklearn.metrics import accuracy_score

"""**Import Data**"""

train=pd.read_csv('train.csv')
test=pd.read_csv('test.csv')

"""**Explore the Data**"""

train.head()

train.tail()

train.shape

train.info()

train.describe()

nu=train.isnull().sum()
nu[nu>0]

sns.heatmap(train.isnull())

"""**Clean Data**"""

def clean(d):                                                               ##def a function
    d.drop(['Name','Cabin','Fare','Ticket','Embarked'],axis=1,inplace=True) ##Delet colum
    d.Age=d.Age.fillna(d.Age.median())                                      ##Fill coolum Age with the average of Age colum
    d.dropna()
    return d                                                          ##Drop all Null data

clean(train)

clean(test)

sns.heatmap(train.isnull())

#train['Sex'] = train['Sex'].map({'male': 0, 'female': 1})
#train.drop('Sex', axis=1, inplace=True)

"""**Data Analysis**"""

train.Sex.value_counts()

train.Sex.value_counts().plot.pie(autopct='%0.2f%%')

sns.countplot(train.Sex)

sns.histplot(train.Age)

"""Transform Data"""

##transform data to numerical
train['Sex'] = train['Sex'].map({'male': 0, 'female': 1})
#train.Sex =pd.get_dummies(train.Sex)

train.info()

train

test['Sex'] = test['Sex'].map({'male': 0, 'female': 1})

test

"""**Create Model**"""

x= train.drop(['Survived'],axis=1)
y= train.Survived

x_train , x_test , y_train , y_test = train_test_split(x,y,train_size=0.8)  #80% train -- 20%test

model1=DecisionTreeClassifier()
model1.fit(x_train,y_train)

pre=model1.predict(x_test)

accuracy_score(pre,y_test)

accuracies=[]

def all(model):
  model.fit(x_train,y_train)
  pre=model1.predict(x_test)
  accuracy=accuracy_score(pre,y_test)
  print('accuracy =',accuracy)
  accuracies.append(accuracy)

model1=LogisticRegression()
all(model1)

model2=RandomForestClassifier()
all (model2)

model3= GradientBoostingClassifier()
all(model3)

model4=DecisionTreeClassifier()
all (model4)

model5 = KNeighborsClassifier()
all(model5)

model6 = GaussianNB()
all(model6)

model7 = SVC()
all(model7)

algorithms =['LogisticRegression','RandomForestClassifier','GradientBoostingClassifier','DecisionTreeClassifier','KNeighborsClassifier','GaussianNB','SVC']

New=pd.DataFrame({'algorithms =': algorithms ,'accuracies = ':accuracies})

New

modelx=GradientBoostingClassifier()
modelx.fit(x_train,y_train)

pred=modelx.predict(test)

final=test.PassengerId

new_dataframe=pd.DataFrame({'PassengerId = ':final,'Survived = ':pred})

new_dataframe

